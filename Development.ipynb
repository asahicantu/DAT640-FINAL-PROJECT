{"cells":[{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# DAT-640  Information Retrieval and Text Mining\n## Final Project: MS-MARCO Document Re-Ranking\n### Autors:\n* **Asahi Cantu - 253964**\n* **Shaon Rahman - StudentID**\n\n### Project Description:\nMicrosoft MAchine Reading COmprehension Dataset  is a copmilation of queries and documents retrieved from Microsoft Bing Platform. It contains a big dataset ~ 22GB of documents and queries"},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Section I - Package installation and definition"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T17:21:18.643468Z","start_time":"2020-11-13T17:20:46.287499Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"!pip install requests\n!pip install elasticsearch\n!pip install tqdm\n!pip install xgboost\n!pip install tensorflow\n!pip install sklearn\n!pip install sentence-transformers\n!pip install matplotlib\n!pip install pytorch-transformers\n!pip install bert-extractive-summarizer","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T17:21:20.070974Z","start_time":"2020-11-13T17:21:19.629474Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"import gzip\nimport math\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\nimport pandas as pd\nimport pytest\nimport pickle\nimport platform\n\nimport random\nimport requests\nimport tarfile\nimport time\nimport timeit\nimport torch\nimport subprocess\nimport sys\nimport tensorflow as tf\nimport xgboost\nimport zipfile\n\nfrom subprocess import Popen,PIPE\n\n\nfrom collections import Counter\nfrom collections import defaultdict\nfrom elasticsearch import Elasticsearch\n\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn import svm\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tqdm.notebook import tqdm\n\nfrom transformers import *\nfrom summarizer import Summarizer\nfrom sentence_transformers import SentenceTransformer, util\n\nimport sklearn.metrics.pairwise\n\nfrom sklearn.metrics import jaccard_score\nimport scipy\nfrom tqdm import tnrange\nimport re","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Section II - Document extraction function definition"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:27:50.439885Z","start_time":"2020-11-13T02:27:50.32932Z"},"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","hidden":true,"trusted":true},"cell_type":"code","source":"def save_pickle(file_path,obj):\n    with open(file_path, 'wb') as handle:\n        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n\ndef load_pickle(file_path):\n    with open(file_path, 'rb') as handle:\n        obj = pickle.load(handle)\n    return obj\n\ndef finished(n=1):\n    file_path = os.path.join('..','assets','bell.wav')\n    for i in range(n):\n        playsound(file_path)\n        time.sleep(1.5)\n\ndef download_file(target_path,url,override=False):\n    local_filename = url.split('/')[-1]\n    # NOTE the stream=True parameter below\n    file_downloaded = False\n    file_path = os.path.join(target_path,local_filename)\n    byte_pos = 0\n    if target_path != '' and not os.path.exists(target_path):\n        os.mkdir(target_path)\n    if not override and os.path.exists(file_path):\n        print(f'\\tFile {file_path} already exists, skipping...')\n        return file_path\n    try:\n        os.remove(file_path)\n    except OSError:\n        pass\n    print(f'Getting file from {url}')\n    while not file_downloaded:\n        resume_header = {f'Range': 'bytes=%d-' % byte_pos}\n        try:\n            with requests.get(url, headers=resume_header, stream=True,  verify=False, allow_redirects=True) as r:\n            #with requests.get(url, stream=True) as r:\n                r.raise_for_status()\n                for chunk in  r.iter_content(chunk_size=8192):\n                    with open(file_path, 'ab') as f:\n                        # If you have chunk encoded response uncomment if\n                        # and set chunk_size parameter to None.\n                        #if chunk: \n                        f.write(chunk)\n                        byte_pos += 1\n                file_downloaded = True\n        except:\n            print(f'An error occured while downloading. Retrying...{sys.exc_info()[0]} {sys.exc_info()[1]}')\n    return file_path\n\ndef clear_indices(excluded_indices= []):\n    for index in  [index for index  in es.indices.stats()['indices'].keys() if index not in excluded_indices]:\n        es.indices.delete(index)\n        \ndef create_index(es,index_name,body,overwrite = False):\n    indices = es.indices.stats()['indices'].keys()\n    if index_name in  indices:\n        if overwrite:\n            print(f'overwriting index {index_name}')\n            es.indices.delete(index_name)\n        else:\n            print(f'Index {index_name} already exists')\n    else:\n        es.indices.create(index_name,body=body)\n        \ndef extract_zip_files(file_path,out_path=None):\n    if not out_path:\n        out_path  = file_path.replace('.zip','')\n    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n        zip_ref.extractall(out_path)\n    return out_path\n\n        \ndef extract_gz_files(file_path,override=False,n=8,max_n=None):\n    x_file_out_path = file_path.replace('.gz','')\n    if override:\n        try:\n            os.remove(x_file_out_path)\n        except OSError:\n            pass\n    if os.path.exists(x_file_out_path):\n        print(f'\\tFile {x_file_out_path} already exists, skipping...')\n    else:\n        print(f'\\tExtracting file {file_path}')\n        gz_file = gzip.GzipFile(file_path, 'rb')\n        n_i = 0\n        while True:\n            chunk = gz_file.read(n)\n            n += len(chunk)\n            if chunk == b'' or (max_n and n_i > max_n):\n                break\n            x_file_out = open(x_file_out_path, 'ab')\n            x_file_out.write(chunk)\n            x_file_out.close()\n        gz_file.close()\n        print(f'\\t\\tExtracted {x_file_out_path}!')\n    return x_file_out_path\n\ndef get_gz_lines(file_path):\n    total_lines = 0\n    with gzip.GzipFile(file_path,'rb') as file:\n        try:\n            while True:\n                next(file)\n                total_lines +=1\n        except StopIteration:\n            pass\n    return total_lines\n                    \ndef get_lines(file_path):\n    total_lines = 0\n    with open(file_path,'rb') as file:\n        try:\n            while True:\n                next(file)\n                total_lines +=1\n        except StopIteration:\n            pass\n    return total_lines\n\ndef get_samples_from_file(file,doc_lines, doc_samples):\n    samples = []\n    for i in tqdm(range(doc_lines)):\n        line = next(file)\n        if i in doc_samples:\n            samples.append(line)\n    return samples\n\ndef extract_rand_samples_from_gz_file(file_path,sample_factor):\n    doc_lines = get_gz_lines(file_path)\n    doc_samples_count =  int(doc_lines * sample_factor)\n    doc_samples = set()\n    while len(doc_samples) < doc_samples_count:\n        doc_samples.add(random.randint(0,doc_lines-1))     \n    with gzip.GzipFile(file_path,'rb') as file:\n        return get_samples_from_file(file,doc_lines,doc_samples)\n    \ndef extract_rand_samples_from_file(file_path,sample_factor):\n    doc_lines = get_lines(file_path)\n    doc_samples_count =  int(doc_lines * sample_factor)\n    doc_samples = set()\n    while len(doc_samples) < doc_samples_count:\n        doc_samples.add(random.randint(0,doc_lines-1))     \n    with open(file_path,'rb') as file:\n        return get_samples_from_file(file,doc_lines,doc_samples)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Section III - Elastic Search downloading and index creation\n## Downloading and executing a new instance of ElasticSearch\nThe code below uses an automated approach todownload and create an instance of elasticSearch. Skip this if alreay have one\n"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T18:07:20.334973Z","start_time":"2020-11-13T18:07:13.317764Z"},"trusted":true},"cell_type":"code","source":"os_name =platform.system().lower()\nfile_path = ''\nes_process = None\nif not os.path.exists(os.path.join(file_path,'elasticsearch-7.9.3')):\n    if os_name == 'windows':\n            url = 'https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.3-windows-x86_64.zip'\n            file = download_file(file_path,url,override=False)\n            x_file= extract_zip_files(file,file_path)\n    elif os_name == 'linux':\n        url = 'https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.3-linux-x86_64.tar.gz'\n        file = download_file(file_path,url,override=False)\n        x_file = extract_gz_files(file)\n        tar_file = os.path.join(file_path,'elasticsearch-7.9.3-linux-x86_64.tar')\n        subprocess.run(['tar','-xvf',tar_file])\n        os.remove(tar_file)\n        subprocess.run(['useradd','elasticuser'])\n        subprocess.run(['chown','-R','elasticuser',os.path.join(file_path,'elasticsearch-7.9.3')])\n    else:\n        path = 'https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.3-darwin-x86_64.tar.gz'\n        file = download_file('es',path,override=False)\n        x_file = extract_gz_files(file)\n        tar_file = os.path.join(file_path,'elasticsearch-7.9.3-darwin-x86_64.tar')\n        subprocess.run(['tar','-xvf',tar_file])\n        os.remove(tar_file)\n        subprocess.run(['useradd','elasticuser'])\n        subprocess.run(['chown','-R','elasticuser',os.path.join(file_path,'elasticsearch-7.9.3')])\n    os.remove(file)\nelse:\n    print('Elastic Search file already exists, skipping...')\n\nprint('Executing ElasticSearch...')   \ncommand = None\nif os_name == 'windows':\n    command= os.path.join(file_path,'elasticsearch-7.9.3','bin','elasticsearch.bat')\n    es_process = Popen([command])\nelse:\n    command= os.path.join(file_path,'elasticsearch-7.9.3','bin','elasticsearch')\n    es_process = Popen(['su','elasticuser','-c',command])\nprint('Done!')   ","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T18:07:21.511932Z","start_time":"2020-11-13T18:07:21.468937Z"},"trusted":true},"cell_type":"code","source":"FIELDS = ['url','title', 'body']\nINDEX_NAME = 'ms-marco'\nbody = {\n    'mappings': {\n            'properties': {\n                'title': {\n                    'type': 'text',\n                    'term_vector': 'yes',\n                    'analyzer': 'english'\n                },\n                'body': {\n                    'type': 'text',\n                    'term_vector': 'yes',\n                    'analyzer': 'english'\n                }\n            }\n        }\n    }\noverwrite = False # DO NOT CHANGE THIS FLAG!!!\nuser = 'elastic'\npassword = 'IfKREtTr7fCqMYTD8NKE4yBi'\nremote_url = f'https://{user}:{password}@6a0fe46eef334fada72abc91933b54e8.us-central1.gcp.cloud.es.io:9243'\n\n#es = Elasticsearch(hosts=remote_url)\n#Wait 20 seconds until elasticsearch is fully mounted\ntime.sleep(30)\nes = Elasticsearch()\ncreate_index(es,INDEX_NAME,body,overwrite = overwrite)\nprint(es.info())","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Section IV - MS-MARCO Dataset Downloading\n## Download MS-MARCO data if not available yet"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:27:57.809075Z","start_time":"2020-11-13T02:27:57.782081Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"\nurls = [\n'https://msmarco.blob.core.windows.net/msmarcoranking/msmarco-docs-lookup.tsv.gz'\n,'https://msmarco.blob.core.windows.net/msmarcoranking/msmarco-doctrain-queries.tsv.gz'\n,'https://msmarco.blob.core.windows.net/msmarcoranking/msmarco-docdev-queries.tsv.gz'\n,'https://msmarco.blob.core.windows.net/msmarcoranking/msmarco-docdev-top100.gz'\n,'https://msmarco.blob.core.windows.net/msmarcoranking/msmarco-docdev-qrels.tsv.gz'\n,'https://msmarco.blob.core.windows.net/msmarcoranking/docleaderboard-queries.tsv.gz'\n,'https://msmarco.blob.core.windows.net/msmarcoranking/docleaderboard-top100.tsv.gz'\n,'https://msmarco.blob.core.windows.net/msmarcoranking/msmarco-docs.tsv.gz'\n]\n\nsource_path = os.path.join(file_path,'MS-MARCO')\n\nif not os.path.isdir(source_path):\n        os.mkdir(source_path)\n\n\ngzfiles = []\nfor url in urls:\n    gzfile = download_file(source_path,url,override=False)\n    gzfiles.append(gzfile)","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Section V - Document sampling and extraction\n## Will extract the 10% of dev queries and related documents for indexing and feature extraction\n"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:27:59.8216Z","start_time":"2020-11-13T02:27:59.803573Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"DOCUMENT_SAMPLE_FACTOR= 0.1\nrandom.seed(1111)","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Query samples come in the form of:\n```\n174249\tdoes xpress bet charge to deposit money in your account\n320792\thow much is a cost to run disneyland\n1090270\tbotulinum definition\n1101279\tdo physicians pay for insurance from their salaries?\n201376\there there be dragons comic\n54544\tblood diseases that are sexually transmitted\n118457\tdefine bona fides\n\n```\n\nTherefore each line of code has to be split in 2,where index[0] = Query ID and index[1] = query_text"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:28:01.210811Z","start_time":"2020-11-13T02:28:01.166235Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"query_samples = extract_rand_samples_from_gz_file(os.path.join(source_path,'msmarco-docdev-queries.tsv.gz'),DOCUMENT_SAMPLE_FACTOR)\nquery_samples = [q.decode('UTF-8').replace('\\r\\n','').split('\\t') for q in query_samples]\nquery_samples = {q[0]:q[1] for q in query_samples}\nprint(len(query_samples))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Get top 100 retrieved documents from development dataset for the query ids retrieved from document **msmarco-docdev-top100.gz**.\n100 Documents come in the form of:\n```\n174249 Q0 D3126539 1 -5.99003 IndriQueryLikelihood\n174249 Q0 D978773 2 -6.18444 IndriQueryLikelihood\n174249 Q0 D399803 3 -6.20982 IndriQueryLikelihood\n174249 Q0 D2204704 4 -6.24312 IndriQueryLikelihood\n174249 Q0 D3126541 5 -6.24726 IndriQueryLikelihood\n174249 Q0 D398816 6 -6.27273 IndriQueryLikelihood\n174249 Q0 D2168983 7 -6.29127 IndriQueryLikelihood\n174249 Q0 D3126537 8 -6.30813 IndriQueryLikelihood\n174249 Q0 D3297846 9 -6.32111 IndriQueryLikelihood\n174249 Q0 D531991 10 -6.34283 IndriQueryLikelihood\n174249 Q0 D2479861 11 -6.34364 IndriQueryLikelihood\n\n```\nOnly columns 0,2,3 and 4 are important\n"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:28:03.150246Z","start_time":"2020-11-13T02:28:02.420417Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"query_doc_rankings = defaultdict(dict)\nwith gzip.GzipFile(os.path.join(source_path,'msmarco-docdev-top100.gz'),'rb') as file:\n    try:\n        while True:\n            line = next(file).decode('UTF-8').replace('\\r\\n','').split(' ')\n            query_id = line[0]\n            query_doc_rankings[query_id][line[2]]=[int(line[3]),float(line[4])]\n    except StopIteration:\n        pass\n    \nprint(len(query_doc_rankings))","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Extract all qrels from the file msmarco-docdev-qrels.tsv. \nThis file contains only one relevant document per query andcomes in the form:\n```\n   2 0 D1650436 1\n1215 0 D1202771 1\n1288 0 D1547717 1\n1576 0 D1313702 1\n2235 0 D2113408 1\n2798 0 D2830290 1\n```\nWhere:\n* Column 0 = Query Id\n* Column 1 = Document Id\nThe rest of the columns are irrelevant, since the present document in the file highlights always '1' in column 3 for being a relevant document"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:28:03.684401Z","start_time":"2020-11-13T02:28:03.662372Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"qrels = {}\nwith gzip.GzipFile(os.path.join(source_path,'msmarco-docdev-qrels.tsv.gz'),'rb') as file:\n    try:\n        while True:\n            line = next(file).decode('UTF-8').replace('\\r\\n','').split(' ')\n            query_id = line[0]\n            #if query_id in query_samples:\n            qrels[query_id] = line[2]\n    except StopIteration:\n        pass\nprint(len(qrels))\nQRELS = qrels\n","execution_count":null,"outputs":[]},{"metadata":{"hidden":true},"cell_type":"markdown","source":"Now get all the documents whose document id is present in  query_doc_top100 from 'msmarco-docs.tsv.gz'\nSuch documents come in the form of:\n```\nD250947 https://www.michaeljfox.org/    LATEST FROM THE BLOG    LATEST FROM THE BLOGMOR\n```\nWhere\n* Column 0 = Document id\n* Column 1 = URL\n* Column 2 = Title\n* Column 3 = Body\n\nOnly columns 0, 2 and 3 are important\nOnce documents are extracted they are added to elasticSearch."},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:32:49.260806Z","start_time":"2020-11-13T02:28:27.807336Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"doc_ids = set(qrels.values())\ndoc_query_ids = set([key for keys in query_doc_rankings.values() for key in keys])\ndoc_ids = set(qrels.values())\ndoc_ids = doc_ids.union(doc_query_ids)\ndocs_len = len(doc_ids)\ndocs = {}\nwith gzip.GzipFile(os.path.join(source_path,'msmarco-docs.tsv.gz'),'rb') as file:\n    added_docs = 0\n    try:\n        while True:\n            if added_docs == docs_len:\n                break\n            line = next(file).decode('UTF-8').replace('\\r\\n','').split('\\t')\n            doc_id = line[0]\n            if doc_id in doc_ids:\n                doc= {'title':line[2].strip(),'body':line[3].strip()}\n                docs[doc_id] = doc\n                es.index(index=INDEX_NAME, id=doc_id, body=doc)\n                added_docs +=1\n                print(f'\\rAdded {doc_id}, {added_docs} of {docs_len}...',end='')\n    except StopIteration:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:34:35.691571Z","start_time":"2020-11-13T02:34:35.625577Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"out_path = os.path.join('','out')\nif not os.path.exists(out_path):\n    os.mkdir(out_path)\nsave_pickle(os.path.join(out_path,'query_samples.pickle'),query_samples)\nsave_pickle(os.path.join(out_path,'query_doc_rankings.pickle'),query_doc_rankings)\nsave_pickle(os.path.join(out_path,'docs.pickle'),docs)\nsave_pickle(os.path.join(out_path,'qrels.pickle'),qrels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"query_samples = load_pickle(os.path.join(out_path,'query_samples.pickle'))\nquery_doc_rankings = load_pickle(os.path.join(out_path,'query_doc_rankings.pickle'))\ndocs = load_pickle(os.path.join(out_path,'docs.pickle'))\nqrels = load_pickle(os.path.join(out_path,'qrels.pickle'))","execution_count":null,"outputs":[]},{"metadata":{"heading_collapsed":true},"cell_type":"markdown","source":"# Section VI - Query analytics and feature extraction algorithms"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:34:38.442716Z","start_time":"2020-11-13T02:34:38.367717Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"def analyze_query(es, query, field, index='ms-marco'):\n    \"\"\"Analyzes a query with respect to the relevant index.\n\n    Arguments:\n        es: Elasticsearch object instance.\n        query: String of query terms.\n        field: The field with respect to which the query is analyzed.\n        index: Name of the index with respect to which the query is analyzed.\n\n    Returns:\n        A list of query terms that exist in the specified field among the documents in the index.\n    \"\"\"\n    tokens = es.indices.analyze(index=index, body={'text': query})['tokens']\n    query_terms = []\n    for t in sorted(tokens, key=lambda x: x['position']):\n        ## Use a boolean query to find at least one document that contains the term.\n        hits = es.search(index=index, body={'query': {'match': {field: t['token']}}},\n                         _source=False, size=1).get('hits', {}).get('hits', {})\n        doc_id = hits[0]['_id'] if len(hits) > 0 else None\n        if doc_id is None:\n            continue\n        query_terms.append(t['token'])\n    return query_terms\n\ndoc_term_freqs={}\ndef get_doc_term_freqs(es, doc_id, field, index='toy_index'):\n    \"\"\"Gets the term frequencies of a field of an indexed document.\n\n    Arguments:\n        es: Elasticsearch object instance.\n        doc_id: Document identifier with which the document is indexed.\n        field: Field of document to consider for term frequencies.\n        index: Name of the index where document is indexed.\n\n    Returns:\n        Dictionary of terms and their respective term frequencies in the field and document.\n    \"\"\"\n    if doc_id in doc_term_freqs:\n        return doc_term_freqs[doc_id]\n    tv = es.termvectors(index=index, id=doc_id, fields=field, term_statistics=True)\n    if tv['_id'] != doc_id:\n        return None\n    if field not in tv['term_vectors']:\n        return None\n    term_freqs = {}\n    for term, term_stat in tv['term_vectors'][field]['terms'].items():\n        term_freqs[term] = term_stat['term_freq']\n    doc_term_freqs[doc_id] = term_freqs\n    return term_freqs\n\n\ndef get_query_term_freqs(es, query_terms):\n    \"\"\"Gets the term frequencies of a list of query terms.\n\n    Arguments:\n        es: Elasticsearch object instance.\n        query_terms: List of query terms, analyzed using `analyze_query` with respect to some relevant index.\n\n    Returns:\n        A list of query terms that exist in the specified field among the documents in the index.\n    \"\"\"\n    c = Counter()\n    for term in query_terms:\n        c[term] += 1\n    return dict(c)\n\n\ndef extract_query_features(query_terms, es, index='toy_index'):\n    \"\"\"Extracts features of a query.\n\n        Arguments:\n            query_terms: List of analyzed query terms.\n            es: Elasticsearch object instance.\n            index: Name of relevant index on the running Elasticsearch service.\n        Returns:\n            Dictionary with keys 'query_length', 'query_sum_idf', 'query_max_idf', and 'query_avg_idf'.\n    \"\"\"\n    q_features = {}\n\n    if len(query_terms) == 0:\n        q_features['query_length'] = 0\n        q_features['query_sum_idf'] = 0\n        q_features['query_max_idf'] = 0\n        q_features['query_avg_idf'] = 0\n        return q_features\n\n    q_features['query_length'] = len(query_terms)\n\n    count_docs_with_term = []\n    total_docs_in_index = int(es.cat.count(index=index, params={\"format\": \"json\"})[0]['count'])\n\n    for query in query_terms:\n        res = es.count(index=index, body={\n            'query':\n                {'match':\n                     {'body': query}\n                 }\n        })['count']\n        count_docs_with_term.append(res)\n\n    q_features['query_sum_idf'] = sum([np.log(total_docs_in_index / freq) for freq in count_docs_with_term])\n    q_features['query_max_idf'] = max([np.log(total_docs_in_index / freq) for freq in count_docs_with_term])\n    q_features['query_avg_idf'] = np.mean([np.log(total_docs_in_index / freq) for freq in count_docs_with_term])\n\n    return q_features\n\n\ndef extract_doc_features(doc_id, es, index='toy_index'):\n    \"\"\"Extracts features of a document.\n\n        Arguments:\n            doc_id: Document identifier of indexed document.\n            es: Elasticsearch object instance.\n            index: Name of relevant index on the running Elasticsearch service.\n\n        Returns:\n            Dictionary with keys 'doc_length_title', 'doc_length_body'.\n    \"\"\"\n    doc_features = {}\n\n    terms = get_doc_term_freqs(es, doc_id, 'body', index)\n    if terms is None:\n        doc_features['doc_length_body'] = 0\n    else:\n        doc_features['doc_length_body'] = sum(terms.values())\n\n    terms = get_doc_term_freqs(es, doc_id, 'title', index)\n    if terms is None:\n        doc_features['doc_length_title'] = 0\n    else:\n        doc_features['doc_length_title'] = sum(terms.values())\n\n    return doc_features\n\n\ndef extract_query_doc_features(query_terms, doc_id, es, index='toy_index'):\n    \"\"\"Extracts features of a query and document pair.\n\n        Arguments:\n            query_terms: List of analyzed query terms.\n            doc_id: Document identifier of indexed document.\n            es: Elasticsearch object instance.\n            index: Name of relevant index on the running Elasticsearch service.\n\n        Returns:\n            Dictionary with keys 'unique_query_terms_in_title', 'unique_query_terms_in_body',\n            'sum_TF_title', 'sum_TF_body', 'max_TF_title', 'max_TF_body', 'avg_TF_title', 'avg_TF_body'.\n    \"\"\"\n    q_doc_features = {}\n\n    if len(query_terms) == 0:\n        q_doc_features['unique_query_terms_in_title'] = 0\n        q_doc_features['unique_query_terms_in_body'] = 0\n        q_doc_features['sum_TF_body'] = 0\n        q_doc_features['max_TF_body'] = 0\n        q_doc_features['avg_TF_body'] = 0\n        q_doc_features['sum_TF_title'] = 0\n        q_doc_features['max_TF_title'] = 0\n        q_doc_features['avg_TF_title'] = 0\n        return q_doc_features\n\n    terms_title = get_doc_term_freqs(es, doc_id, 'title', index)\n    terms_body = get_doc_term_freqs(es, doc_id, 'body', index)\n\n    def agg(terms_dict, query_terms_list, func):\n        freq_list = []\n        for term in query_terms_list:\n            if term in terms_dict.keys():\n                freq_list.append(terms_dict[term])\n            else:\n                freq_list.append(0)\n        return func(freq_list)\n\n    if terms_title is None:\n        q_doc_features['sum_TF_title'] = 0\n        q_doc_features['max_TF_title'] = 0\n        q_doc_features['avg_TF_title'] = 0\n    else:\n        q_doc_features['sum_TF_title'] = agg(terms_title, query_terms, sum)\n        q_doc_features['max_TF_title'] = agg(terms_title, query_terms, max)\n        q_doc_features['avg_TF_title'] = agg(terms_title, query_terms, np.mean)\n\n    if terms_body is None:\n        q_doc_features['sum_TF_body'] = 0\n        q_doc_features['max_TF_body'] = 0\n        q_doc_features['avg_TF_body'] = 0\n    else:\n        q_doc_features['sum_TF_body'] = agg(terms_body, query_terms, sum)\n        q_doc_features['max_TF_body'] = agg(terms_body, query_terms, max)\n        q_doc_features['avg_TF_body'] = agg(terms_body, query_terms, np.mean)\n\n    # UNIQUE QUERY TERMS\n    query_terms = set(query_terms)\n    if terms_title is None:\n        q_doc_features['unique_query_terms_in_title'] = 0\n    else:\n        q_doc_features['unique_query_terms_in_title'] = len([t for t in query_terms if t in terms_title.keys()])\n    if terms_body is None:\n        q_doc_features['unique_query_terms_in_body'] = 0\n    else:\n        q_doc_features['unique_query_terms_in_body'] = len([t for t in query_terms if t in terms_body.keys()])\n\n    return q_doc_features\n\n\nFEATURES_QUERY = ['query_length', 'query_sum_idf', 'query_max_idf', 'query_avg_idf']\nFEATURES_DOC = ['doc_length_title', 'doc_length_body']\nFEATURES_QUERY_DOC = ['unique_query_terms_in_title', 'sum_TF_title', 'max_TF_title', 'avg_TF_title',\n                      'unique_query_terms_in_body', 'sum_TF_body', 'max_TF_body', 'avg_TF_body'\n                      ]\n\n\ndef extract_features(query_terms, doc_id, es, index='toy_index'):\n    \"\"\"Extracts query features, document features and query-document features of a query and document pair.\n\n        Arguments:\n            query_terms: List of analyzed query terms.\n            doc_id: Document identifier of indexed document.\n            es: Elasticsearch object instance.\n            index: Name of relevant index on the running Elasticsearch service.\n\n        Returns:\n            List of extracted feature values in a fixed order.\n    \"\"\"\n    feature_vect = []\n\n    query_features = extract_query_features(query_terms, es, index=index)\n    for f in FEATURES_QUERY:\n        feature_vect.append(query_features[f])\n\n    doc_features = extract_doc_features(doc_id, es, index=index)\n    for f in FEATURES_DOC:\n        feature_vect.append(doc_features[f])\n\n    query_doc_features = extract_query_doc_features(query_terms, doc_id, es, index=index)\n    for f in FEATURES_QUERY_DOC:\n        feature_vect.append(query_doc_features[f])\n\n    return feature_vect\n\ndef prepare_ltr_training_data(qrels_dict,query_dict, es, index='ms-marco'):\n    \"\"\"Prepares feature vectors and labels for query and document pairs found in the training data.\n\n        Arguments:\n            qrels_dict: Dictionary of qrels, where the key = query_id, value = relevant document id.\n            query_dict: Dictionary of queries where key = query_id , value = query text\n            es: Elasticsearch object instance.\n            index: Name of relevant index on the running Elasticsearch service.\n\n        Returns:\n            X: List of feature vectors extracted for each pair of query and retrieved or relevant document.\n            y: List of corresponding labels.\n    \"\"\"\n    X = []\n    y = []\n\n    for query_id in tqdm(qrels_dict):\n        relevent_doc = qrels_dict[query_id]\n        query = query_dict[query_id]\n        analyzed_terms = analyze_query(es, query, 'body', index=index)\n\n        extracted_feature = extract_features(analyzed_terms, relevent_doc, es, index=index)\n        X.append(extracted_feature)\n        y.append(1)\n\n        hits = es.search(index=index, q=' '.join(analyzed_terms), _source=True, size=100)['hits']['hits']\n\n        for hit in hits:\n            doc_id = hit['_id']\n            if doc_id != relevent_doc:\n                extracted_feature = extract_features(analyzed_terms, doc_id, es, index=index)\n                X.append(extracted_feature)\n                y.append(0)\n    return X, y\n\ndef get_reciprocal_rank(doc_rankings, relevant_doc_id, ranking_level=1000):\n    \"\"\"Computes Reciprocal Rank (RR). MRR@10\n\n    Args:\n        system_ranking: Ranked list of document IDs.\n        ground_truth: Set of relevant document IDs.\n\n    Returns:\n        RR (float).\n    \"\"\"\n    for i, doc_id in enumerate(doc_rankings):\n        if doc_id == relevant_doc_id:\n            return 1 / (i + 1)\n    return 0\n\ndef get_mean_eval_measure(system_rankings,qrels, eval_function):\n    \"\"\"Computes a mean of any evaluation measure over a set of queries.\n\n    Args:\n        system_rankings: Dict with query ID as key and a ranked list of document IDs as value.\n        ground_truths: Dict with query ID as key and a set of relevant document IDs as value.\n        eval_function: Callback function for the evaluation measure that mean is computed over.\n\n    Returns:\n        Mean evaluation measure (float).\n    \"\"\"\n    sum_score = 0\n    for query_id, system_ranking in system_rankings.items():\n        sum_score += eval_function(system_ranking, qrels[query_id])\n    return sum_score / len(system_rankings)\n\ndef load_basic_rankings(filepath, avoid_queries, max_size=100):\n    basic_rankings = defaultdict(list)\n\n    with open(filepath, 'r') as file:\n        for line in file:\n            line = line.split(' ')\n            query_id = line[0]\n            doc_id = line[2]\n\n            if query_id in avoid_queries:\n                continue\n\n            if query_id not in QRELS.keys():\n                continue\n\n            basic_rankings[query_id].append(doc_id)\n\n            if(len(basic_rankings)) >= max_size:\n                break\n\n        return basic_rankings\n    \ndef rerank_score(basic_rankings,queries,qrels, ltr_model,index_name):\n    reranked = {}\n    for query_id, doc_rankings in tqdm(basic_rankings.items(), desc='Reranking'):\n\n        query = queries[query_id]\n        query_terms = analyze_query(es, query, 'body', index_name)\n\n        if query_terms is None:\n            continue\n\n        features = []\n        for doc_id in doc_rankings:\n            ft = extract_features(query_terms, doc_id, es, index_name)\n            features.append(ft)\n\n        doc_reranked = ltr_model.rank(features, doc_rankings)\n        reranked[query_id] = doc_reranked\n\n    score = get_mean_eval_measure(reranked,qrels, get_reciprocal_rank)\n    return score\n\nclass PointWiseLTRModel(object):\n    def __init__(self, regressor):\n        \"\"\"\n        Arguments:\n            classifier: An instance of scikit-learn regressor.\n        \"\"\"\n        self.model = regressor\n\n    def train(self, X, y):\n        \"\"\"Trains an LTR model.\n\n        Arguments:\n            X: Features of training instances.\n            y: Relevance assessments of training instances.\n        \"\"\"\n        assert self.model is not None\n        self.model = self.model.fit(X, y)\n\n    def rank(self, ft, doc_dict):\n        \"\"\"Predicts relevance labels and rank documents for a given query.\n\n        Arguments:\n            ft: A list of feature vectors for query-document pairs.\n            doc_ids: A dictionary  of document ids with their original scores.\n        Returns:\n            List of tuples, each consisting of document ID and predicted relevance label.\n        \"\"\"\n        assert self.model is not None\n        rel_labels = self.model.predict(np.array(ft))\n        sort_indices = np.argsort(rel_labels)[::-1]\n        results = {}\n        doc_keys = list(doc_dict.keys())\n        for i in sort_indices:\n            doc_key = doc_keys[i]\n            results[doc_key] = doc_dict[doc_key]\n        return results\n    \ndef load_basic_rankings_with_features(filepath, avoid_queries, es, max_size=100, index='ms-marco'):\n    basic_rankings = defaultdict(list)\n    file = None\n    if '.gz' in filepath:\n        with gzip.GzipFile(filepath,'rb') as file:\n            for line in tqdm(file):\n                line = line.decode('UTF-8')\n                record = line.split(' ')\n                query_id = int(record[0])\n                doc_id = record[2]\n\n                if query_id in avoid_queries:\n                    continue\n\n                if query_id not in QRELS.keys():\n                    continue\n\n                query = QUERIES[query_id]\n                analyzed_terms = analyze_query(es, query, 'body', index=index)\n\n                if len(analyzed_terms) == 0:\n                    continue\n\n                extracted_feature = extract_features(analyzed_terms, doc_id, es, index=index)\n                basic_rankings[query_id].append((doc_id, extracted_feature))\n\n                if len(basic_rankings[query_id]) == 100 and len(basic_rankings) >=max_size:\n                    break\n    else:\n        with open(filepath, 'r') as file:\n            for line in tqdm(file):\n                record = line.split(' ')\n                query_id = int(record[0])\n                doc_id = record[2]\n\n                if query_id in avoid_queries:\n                    continue\n\n                if query_id not in QRELS.keys():\n                    continue\n\n                query = QUERIES[query_id]\n                analyzed_terms = analyze_query(es, query, 'body', index=index)\n\n                if len(analyzed_terms) == 0:\n                    continue\n\n                extracted_feature = extract_features(analyzed_terms, doc_id, es, index=index)\n                basic_rankings[query_id].append((doc_id, extracted_feature))\n\n                if len(basic_rankings[query_id]) == 100 and len(basic_rankings) >=max_size:\n                    break\n\n    return basic_rankings\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Section VII - Baseline Model - ML Algorithms for Document Re-ranking"},{"metadata":{},"cell_type":"markdown","source":"## Get 80% random samples for a given set to be used as train data"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T17:17:42.450895Z","start_time":"2020-11-13T17:17:42.443382Z"},"trusted":true},"cell_type":"code","source":"LTR_MODELS = {}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:34:40.350246Z","start_time":"2020-11-13T02:34:40.329219Z"},"trusted":true},"cell_type":"code","source":"train_data_factor = 0.8\nq_keys = list(query_samples.keys())\ntrain_qrels = set()\ntest_qrels = set()\n\nq_len = int(len(query_samples) * train_data_factor)\nwhile len(train_qrels) < q_len:\n    idx = random.randint(0,len(query_samples)-1)\n    train_qrels.add(q_keys[idx])\ntest_qrels = set(q_keys).difference(train_qrels)\ntrain_qrels = {k:qrels[k] for k in train_qrels}\ntest_qrels = {k:qrels[k] for k in test_qrels}\n\nQUERIES = {key:val for key, val in query_samples.items() if key in train_qrels or key in test_qrels}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:35:27.268116Z","start_time":"2020-11-13T02:35:27.018934Z"},"trusted":true},"cell_type":"code","source":"train_query_ids = list(qrels.keys())\ntrain_data_path = os.path.join(out_path,'training_data.pickle')\nif os.path.isfile(train_data_path):\n    with open(train_data_path, 'rb') as file:\n        training_data = pickle.load(file)\nelse:\n    training_data = prepare_ltr_training_data(train_qrels,query_samples, es, index=INDEX_NAME)\n    with open(train_data_path, 'wb') as file:\n        pickle.dump(training_data, file)\nX_train, y_train = training_data\nbasic_rankings = {k:query_doc_rankings[k] for k in test_qrels}","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:35:28.352707Z","start_time":"2020-11-13T02:35:28.338709Z"},"trusted":true},"cell_type":"code","source":"base_score = get_mean_eval_measure(basic_rankings,qrels, get_reciprocal_rank)\nprint('Base Score:', base_score)\nLTR_MODELS['Base'] =  base_score","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:38:51.710909Z","start_time":"2020-11-13T02:35:29.559709Z"},"trusted":true},"cell_type":"code","source":"clf = RandomForestRegressor(max_depth=3, random_state=0, n_jobs=4, n_estimators=11)\nltr = PointWiseLTRModel(clf)\nltr.train(X_train, y_train)\nrf_score = rerank_score(basic_rankings,query_samples,qrels, ltr,INDEX_NAME)\nprint('Random Forest Score:', rf_score)\nLTR_MODELS['RandForest'] =  rf_score","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:42:18.804283Z","start_time":"2020-11-13T02:38:52.679255Z"},"trusted":true},"cell_type":"code","source":"clf = xgboost.XGBRegressor(max_depth=3, random_state=0, base_score=0.2,objective='reg:linear', verbosity=0, n_estimators=11)\nltr = PointWiseLTRModel(clf)\nltr.train(np.array(X_train), np.array(y_train))\nxb_score = rerank_score(basic_rankings,query_samples,test_qrels, ltr,INDEX_NAME)\nprint('XGBoost Score:', xb_score)\nLTR_MODELS['XGBoost'] =  xb_score","execution_count":null,"outputs":[]},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T02:55:41.114624Z","start_time":"2020-11-13T02:42:19.841881Z"},"trusted":true},"cell_type":"code","source":"clf = LinearRegression(normalize=True)\nltr = PointWiseLTRModel(clf)\nltr.train(np.array(X_train), np.array(y_train))\nltr_score = rerank_score(basic_rankings,query_samples,test_qrels, ltr,INDEX_NAME)\nprint('Linear Score:',ltr_score )\nLTR_MODELS['LinReg'] =  ltr_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Section IX - Advanced Model - Deep Learning with BERT Document Re-ranking"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T15:05:46.573226Z","start_time":"2020-11-13T15:03:45.729172Z"},"trusted":true},"cell_type":"code","source":"custom_config = AutoConfig.from_pretrained(\"distilbert-base-cased\")\ncustom_config.output_hidden_states=True\ncustom_tokenizer = AutoTokenizer.from_pretrained('distilbert-base-cased')\ncustom_model = AutoModel.from_pretrained('distilbert-base-cased', config=custom_config)\nembedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens',device='cuda') #BERT BASE\n#'bert-base-nli-mean-tokens'\n#'distilbert-base-nli-stsb-mean-tokens'\nmodel = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Perform text sumamrization for the queries samples to"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T16:59:34.49734Z","start_time":"2020-11-13T16:49:29.249Z"},"heading_collapsed":true},"cell_type":"markdown","source":"## Summarize the whole corpus to diminish time and tokenize document"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T16:59:33.069476Z","start_time":"2020-11-13T16:35:36.651313Z"},"hidden":true,"trusted":true},"cell_type":"code","source":"docs_sum = {}\ndoc_ids = set([doc_id for docs_dict in basic_rankings.values() for doc_id in docs_dict.keys()])\n#doc_ids = set([doc_id for d in {q_id:query_doc_rankings[q_id] for q_id in test_qrels}.values() for doc_id in d ])\n\n#doc_ids = doc_ids.union( set([qrels[k] for k in  qrels if k in basic_rankings.keys() ]) )\ndoc_ids = doc_ids.union( set([qrels[k] for k in  qrels if k in test_qrels ]) )\nfor doc_id in tqdm(doc_ids):\n    doc = docs[doc_id]\n    doc_title =  doc['title']\n    doc_body = doc['body']\n    summary = model(doc_body,min_length=250, max_length=500)\n    docs_sum[doc_id] = (doc_title, summary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with gzip.GzipFile(os.path.join('out','summarized_docs_test.tsv.gz'), 'wb') as gzf:\n    for doc_id in docs_sum:\n        gzf.write(f'{doc_id}\\t{docs_sum[doc_id][0]}\\t{docs_sum[doc_id][1]}\\n'.encode('UTF-8'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Find the closest 100 documents of the corpus for each query sentence based on cosine similarity"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T17:14:25.348403Z","start_time":"2020-11-13T17:11:59.827102Z"},"trusted":true},"cell_type":"code","source":"test_queries = list(basic_rankings.keys())\ncorpus_embeddings=embedder.encode([d[1] for d in list(docs_sum.values())],num_workers=4,device='cuda')\nquery_embeddings_dict = dict(zip(test_queries,embedder.encode(test_queries,num_workers=4,device='cuda')))\ncorpus_embeddings_dict  = dict(zip(docs_sum.keys(),corpus_embeddings))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_pickle('query_embeddings2.pkl',query_embeddings_dict)\nsave_pickle('corpus_embeddings2.pkl',corpus_embeddings_dict)\nsave_pickle('ranks2.pkl',basic_rankings)\nsave_pickle('qrels.pkl',qrels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reranked_docs = defaultdict(dict)\ndoc_keys = list(docs.keys())\nfor query_id, query_embedding in tqdm(query_embeddings_dict.items()):\n    doc_ids = list(basic_rankings[query_id].keys())\n    if not qrels[query_id] in doc_ids:\n        continue\n    doc_embeddings =  [corpus_embeddings_dict[doc_id] for doc_id in doc_ids ]\n    distances= cosine_similarity([query_embedding], doc_embeddings)[0]\n    results = zip(doc_ids, distances)\n    results = sorted(results, key=lambda x: x[1],reverse=True)\n    for doc_id,score in results:\n        reranked_docs[query_id][doc_id]=[doc_ids.index(doc_id)+1,score]\n    adv_score = get_mean_eval_measure(reranked_docs,qrels, get_reciprocal_rank)\n\n\nadv_score = get_mean_eval_measure(reranked_docs,qrels, get_reciprocal_rank)\nprint('Advanced Model Score:', adv_score )\nLTR_MODELS['BERT'] =  adv_score","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Results\n## Given the random samples and document reranking the following results are given"},{"metadata":{"trusted":true},"cell_type":"code","source":"LTR_MODELS = {k:LTR_MODELS[k] for k in sorted(LTR_MODELS,key=lambda x:LTR_MODELS[x],reverse=True)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(LTR_MODELS.keys(),LTR_MODELS.values())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning Variables"},{"metadata":{"ExecuteTime":{"end_time":"2020-11-13T18:07:53.059667Z","start_time":"2020-11-13T18:07:53.047087Z"},"trusted":false},"cell_type":"code","source":"es_process.kill()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}